{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f7ce9d-679c-499f-8415-a580cd56a756",
   "metadata": {},
   "source": [
    "# Spatial Transcriptomics Demo of HM-OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d340a388-356e-4796-87f0-4f912cc46dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import torch\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.HiddenMarkovOT as HiddenMarkovOT\n",
    "import src.utils.util_LR as util_LR\n",
    "from src.utils.util_LR import convert_adata\n",
    "import src.plotting as plotting\n",
    "util_LR.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3e50c-1cb3-44e8-9f42-04c117693c4f",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "For this demonstration, we use spatial transcriptomics data from **Chen et al. (2022)**  \n",
    "([Cell, 2022](https://www.cell.com/cell/fulltext/S0092-8674(22)00399-3)),  \n",
    "which mapped mouse embryonic development at single-cell resolution with Stereo-Seq.\n",
    "\n",
    "The data is publicly available via the [MOSTA](https://db.cngb.org/stomics/datasets/STDS0000058/data) database.\n",
    "\n",
    "We select spatial datasets from three developmental stages for this first example:\n",
    "\n",
    "- **E10.5**\n",
    "- **E11.5**\n",
    "- **E12.5**\n",
    "\n",
    "We first preprocess the data minimally, annotating each with timepoints, intersecting common genes, concatenating and then performing a consistent normalization, log-transform, and joint PCA for a set of common embeddings of the varied timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33a0c61-cf1a-41b5-8c0e-481ed880e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mouse-embryo AnnDatas\n",
      "Starting PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph3641/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/ph3641/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filehandles_embryo_adata = [\n",
    "                            '/scratch/gpfs/ph3641/mouse_embryo/E11.5_E1S1.MOSTA.h5ad', \\\n",
    "                            '/scratch/gpfs/ph3641/mouse_embryo/E12.5_E1S1.MOSTA.h5ad', \\\n",
    "                            '/scratch/gpfs/ph3641/mouse_embryo/E13.5_E1S1.MOSTA.h5ad']\n",
    "\n",
    "timepoints = [ 'E11.5', 'E12.5', 'E13.5'] \n",
    "\n",
    "# Load adatas and set count layer and timepoints\n",
    "print('Loading mouse-embryo AnnDatas')\n",
    "adatas = []\n",
    "for i, fh in enumerate(filehandles_embryo_adata):\n",
    "    adata = sc.read_h5ad(fh)\n",
    "    adata.X = adata.layers['count']\n",
    "    adata.obs['timepoint'] = [timepoints[i]] * adata.shape[0]\n",
    "    adatas.append(adata)\n",
    "\n",
    "# Find intersection of genes across all adatas\n",
    "common_genes = set(adatas[0].var.index)\n",
    "for adata in adatas[1:]:\n",
    "    common_genes &= set(adata.var.index)\n",
    "common_genes = list(common_genes)\n",
    "\n",
    "# Subset each adata to the common genes\n",
    "adatas = [adata[:, common_genes] for adata in adatas]\n",
    "adata_pairs = []\n",
    "\n",
    "print('Starting PCA')\n",
    "\n",
    "# Compute pairwise PCA (so it's scalable) for each AnnData (t, t+1)\n",
    "for i in range(len(adatas) - 1):\n",
    "    ad1, ad2 = adatas[i], adatas[i+1]\n",
    "    t1, t2 = timepoints[i], timepoints[i+1]\n",
    "    \n",
    "    # 1) Normalize + log-transform both slices independently\n",
    "    joint = ad.concat([ad1, ad2], join='inner')\n",
    "    sc.pp.normalize_total(joint)\n",
    "    sc.pp.log1p(joint)\n",
    "    sc.pp.pca(joint, n_comps=30)\n",
    "    # Free up memory by clearing X and heavy layers\n",
    "    joint.X = None\n",
    "    if 'count' in joint.layers:\n",
    "        del joint.layers['count']\n",
    "    adata_pairs.append(joint)\n",
    "\n",
    "print('PCA Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9df35-4484-4d41-95e5-10e1d06860f1",
   "metadata": {},
   "source": [
    "### Running HM-OT\n",
    "\n",
    "Now that we’ve constructed an `AnnData` object containing:\n",
    "\n",
    "- The **timepoints** of interest (in `.obs['timepoint']`)\n",
    "- **Lower-dimensional features** for cost computation (in `.obsm['X_pca']`)\n",
    "- **Cell-type annotations** (in `.obs['annotation']`)\n",
    "- **Spatial coordinates** (in `.obs[['x_loc', 'y_loc']]` or `.obsm['spatial']`)\n",
    "\n",
    "...we're ready to run **Hidden Markov Optimal Transport (HM-OT)** (again)!\n",
    "\n",
    "Since this is a **spatial transcriptomics dataset**, we set `spatial=True` in the preprocessing.\n",
    "\n",
    "As before, we configure the low-rank approximation parameters for the pairwise distance matrices:\n",
    "\n",
    "- `dist_rank` — the rank for approximating the **inter-timepoint cost matrix** $C^{(t,t+1)}$\n",
    "- `dist_rank_2` — the rank for approximating the **intra-timepoint cost matrices** $A^{(t)}$ (used when spatial structure is available)\n",
    "- `dist_eps` — the allowed approximation error (higher values relax the low-rank accuracy)\n",
    "\n",
    "As before, lowering `dist_rank` or increasing `dist_eps` reduces memory usage and speeds up computations, at the cost of reduced approximation fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b0023c-2b6d-4e2f-a18e-b1cdb82296c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.utils.util_LR import convert_adata_pairwise\n",
    "\n",
    "# Set torch device (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert AnnData in HM-OT ready factors\n",
    "C_factors_sequence, A_factors_sequence, Qs, labels, rank_list, spatial_list = convert_adata_pairwise(adata_pairs,\n",
    "                                                                                    timepoints=timepoints,\n",
    "                                                                                     timepoint_key = 'timepoint',\n",
    "                                                                                     replicate_key = 'embryo_id',\n",
    "                                                                                     feature_key = 'X_pca',\n",
    "                                                                                     cell_type_key = 'annotation',\n",
    "                                                                                     spatial = True,\n",
    "                                                                                     spatial_key = ['x_loc', 'y_loc'],\n",
    "                                                                                     fallback_spatial_key = 'spatial',\n",
    "                                                                                     dist_eps = 0.02,\n",
    "                                                                                     dist_rank = 100,\n",
    "                                                                                     dist_rank_2 = 50,\n",
    "                                                                                     device = device,\n",
    "                                                                                    normalize=True\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767ef90-8894-4bc7-9af3-0db873d873a5",
   "metadata": {},
   "source": [
    "### Building a Differentiation Map with Spatial Information\n",
    "\n",
    "Now, we're ready to run **HM-OT** on the preprocessed spatial transcriptomics data.\n",
    "\n",
    "In this example, we infer the sequence of differentiation maps $(\\mathbf{T}^{(t,t+1)})_{t=1}^{n-1}$ across the selected timepoints.\n",
    "\n",
    "Since spatial coordinates are available, we introduce an additional parameter, $\\alpha$, which balances expression-based and spatial-based costs.\n",
    "\n",
    "- Setting $\\alpha = 0$ recovers the standard single-cell variant of HM-OT, using only gene expression information.\n",
    "- Increasing $\\alpha > 0$ progressively upweights the contribution of spatial proximity in the transport problem.\n",
    "\n",
    "This allows HM-OT to flexibly integrate both transcriptomic and spatial information when modeling cell-state transitions. In particular, when $\\alpha > 0$, the objective solved by HM-OT becomes a **fused Gromov-Wasserstein (FGW)** loss, which simultaneously accounts for both feature and spatial structure. Another key hyperparameter is **$\\gamma$**, which controls the level of **entropy regularization** which scales as **$1/\\gamma$**:\n",
    "\n",
    "- Higher values of $\\gamma$ produce sharper and more deterministic transitions between clusters.\n",
    "- Lower values of $\\gamma$ allow for softer and more distributed transitions, which may better capture gradual differentiation.\n",
    "\n",
    "Choosing $\\alpha$ and $\\gamma$ appropriately is important for correctly capturing differentiation.\n",
    "\n",
    "The low-rank optimal transport solver used for FGW here is based on the framework introduced in:\n",
    "\n",
    "> Halmos, P., Liu, X., Gold, J., and Raphael, B. (2024). \n",
    "> [Low-Rank Optimal Transport through Factor Relaxation with Latent Coupling](https://proceedings.neurips.cc/paper_files/paper/2024/file/cfc1924c62e72e2cb0e0feeecb963241-Paper-Conference.pdf), NeurIPS 2024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f39b06-b811-482a-9cc7-bc12c7623bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize HM-OT with hyperparameters, set printCost = True to see progress on loss\n",
    "\n",
    "hmot = HiddenMarkovOT.HM_OT(rank_list,\n",
    "                            tau_in = 1e-3,\n",
    "                            tau_out = 1e-3,\n",
    "                            gamma = 80,\n",
    "                            max_iter = 30,\n",
    "                            min_iter = 30,\n",
    "                            device=device,\n",
    "                            alpha = 0.9999,\n",
    "                            dtype=torch.float32,\n",
    "                            printCost=False,\n",
    "                            returnFull=False,\n",
    "                            initialization='Full'\n",
    "                            )\n",
    "\n",
    "# Run HM-OT to infer annotated transitions\n",
    "hmot.impute_annotated_transitions(C_factors_sequence, A_factors_sequence, Qs)\n",
    "\n",
    "# We can now load the transitions and annotated cell-types\n",
    "Ts_hmot = [T.cpu().numpy() for T in hmot.T_gammas]\n",
    "Qs_ann = [Q.cpu().numpy() for Q in Qs]\n",
    "\n",
    "# Visualize the inferred differentiation map\n",
    "plotting.diffmap_from_QT(Qs_ann, Ts_hmot, labels, dsf=0.01, fontsize=6, linethick_factor=20, \\\n",
    "                         title= f'Example Differentiation Map: {timepoints[0]} to {timepoints[1]} to {timepoints[2]}',\n",
    "                        save_name = os.path.join(\"/scratch/gpfs/ph3641/hm_ot/ME_supervised_figs/diff_map_ME_Demo.png\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1b0d2-af1d-4f30-b2f4-61225c6a3b30",
   "metadata": {},
   "source": [
    "### Mapping Annotated Cell-Types Through Time\n",
    "\n",
    "Once HM-OT has inferred the transitions between timepoints, we can propagate cluster or cell-type annotations through time.\n",
    "\n",
    "- Setting a **reference index** allows you to choose where to start the mapping.\n",
    "- Choosing an **early timepoint** (small `reference_index`) tracks **descendants** forward through development.\n",
    "- Choosing a **late timepoint** (larger `reference_index`) traces **ancestors** backward in time.\n",
    "\n",
    "Below, we visualize the differentiation trajectory starting from different reference timepoints. If this exceeds memory limitations for a dataset, set `full_P=False`. This will be slower but compute the clustering in a much more space efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c909cbc-f915-491b-a373-1c2344c656b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotting)\n",
    "\n",
    "# Tracking descendant cells backward in time\n",
    "plotting.plot_clusters_from_QT(\n",
    "            spatial_list, Qs_ann, Ts_hmot, None, \n",
    "            clustering_type='reference', \n",
    "            reference_index=2, \n",
    "            flip=True, \n",
    "            dotsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831d57e-7fda-4c78-bead-c775c5f78de5",
   "metadata": {},
   "source": [
    "![Alt text](E11.5_12.5_13.5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a762b6-1391-4b39-a28e-0813ba8fafeb",
   "metadata": {},
   "source": [
    "### Co-cluster Inference Through Transfer\n",
    "\n",
    "In this example, we demonstrate how **HM-OT** can be used for **cluster-transfer** and **missing annotation imputation** in partially labeled datasets. \n",
    "\n",
    "Suppose one has $n$ datasets where $n-r$ have known annotations and $r$ datasets have missing or incomplete annotations. **HM-OT** can be used to transfer the annotations across samples, even when data which is not necessarily temporal, so long as all datasets share a common space (e.g. spatial coordinates, expression coordinates, both, and so on). This enables **semi-supervised** or **unsupervised** clustering in sequential data.\n",
    "\n",
    "When learning \"unsupervised\" clusters, one can freely choose a number of key variables of interest:\n",
    "\n",
    "- `proportions`: a list of $n$ 1D `torch.Tensor` objects specifying the desired cell-type proportions for each dataset.  \n",
    "  If set to `False` (default), proportions are initialized uniformly and learned during optimization.\n",
    "- `tau_in`: a (mirror-descent) step-size variable for the learning proportions. Setting `tau_in` larger (e.g. `tau_in=1000`) means the step-size will be smaller, which tends to be more stable. Smaller `tau_in` allows for faster deviations from the initial default proportions (uniform or the user input proportions) but may be less stable.\n",
    "- `rank_list`: list of tuples `[(r₁, r₂), (r₂, r₃), ...]` specifying the number of clusters at each timepoint pair. These define the dimensions of the soft cluster assignment matrices and the rank of the low-rank OT maps.\n",
    "- `tau_out`: regularization strength controlling how much mass is allowed to vary across the marginal distributions $(a_t)_{t=1}^n$. Larger values encourage more strictly balanced mappings across timepoints; smaller values allow more mass shift.\n",
    "- `Qs_IC`: initial conditions for the cluster assignments. This is a list of cluster assignment matrices (tensors) used to warm-start the optimization.\n",
    "- `Qs_freeze`: list of booleans specifying which timepoints have **fixed** clusters (True) and which are **learned** (False). This allows labeled datasets to propagate cluster identities to unlabeled datasets.\n",
    "- `warmup`: whether to perform a warm-start round on the transitions $(\\mathbf{T}^{(t,t+1)})_{t=1}^{n-1}$ before inferring the clusterings. This is useful when all timepoints have annotated labels and you want to initialize the transitions before learning cluster assignments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefd236-756a-48a4-8c94-c86e1de08ccd",
   "metadata": {},
   "source": [
    "### One-Way Cluster Transfer Example\n",
    "\n",
    "As a concrete demonstration of semi-supervised cluster inference, we perform a **simple pairwise transfer** of annotations.\n",
    "\n",
    "In this case, we assume that only the **first** dataset is annotated. Using HM-OT, we propagate those cluster labels **forward** to the second dataset, without requiring a ground-truth clustering for the second timepoint.\n",
    "\n",
    "We do this by setting:\n",
    "\n",
    "- `Qs_freeze = [True, False]`: freezing the clustering on the first timepoint and learning it on the second.\n",
    "- `Qs_IC`: providing a known cluster assignment (Q matrix) only for the first timepoint.\n",
    "- `warmup = False`: we skip warm-starting the transitions, and infer both the map and the clusters jointly.\n",
    "\n",
    "This setup demonstrates how HM-OT can serve as a **cluster transfer mechanism** across timepoints, conditions, batches, or a spatial axis — even in spatial or non-transcriptomic settings.\n",
    "\n",
    "Below, we visualize the transferred clusters at both timepoints, using a forward-propagation from the annotated sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93b640-f3fa-4451-8635-9fb35428f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(HiddenMarkovOT)\n",
    "\n",
    "# Initialize HM-OT\n",
    "hmot_partial = HiddenMarkovOT.HM_OT(\n",
    "                            rank_list[:-1],\n",
    "                            tau_in = 1e-3,\n",
    "                            tau_out = 1e-3,\n",
    "                            gamma = 80,\n",
    "                            max_iter = 30,\n",
    "                            min_iter = 30,\n",
    "                            device=device,\n",
    "                            alpha = 0.9999,\n",
    "                            dtype = torch.float32,\n",
    "                            printCost = False,\n",
    "                            returnFull = False,\n",
    "                            initialization = 'Full'\n",
    "                           )\n",
    "\n",
    "# Run HM-OT with Qs_IC from only timepoint 1, and freeze it\n",
    "hmot_partial.gamma_smoothing(C_factors_sequence[:-1],\n",
    "                     A_factors_sequence[:-1],\n",
    "                     Qs_IC = [Qs[0], None],\n",
    "                     Qs_freeze = [True, False],\n",
    "                    warmup = False\n",
    "                    )\n",
    "\n",
    "# Extract outputs\n",
    "Qs_hmot_partial = [Q.cpu().numpy() for Q in hmot_partial.Q_gammas]\n",
    "Ts_hmot_partial = [T.cpu().numpy() for T in hmot_partial.T_gammas]\n",
    "\n",
    "# Visualize the transfer from time 1 to time 2\n",
    "plotting.plot_clusters_from_QT(spatial_list[:-1], Qs_hmot_partial,\n",
    "                               Ts_hmot_partial, None, clustering_type='reference',\n",
    "                               reference_index=0, flip=True, dotsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6aff5b-9d94-4377-9296-558e56c02627",
   "metadata": {},
   "source": [
    "![Alt text](Cluster_Transfer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8de734-7e7f-4ed7-9892-72d0309dd697",
   "metadata": {},
   "source": [
    "### One-Way Cluster Transfer Example 2\n",
    "\n",
    "We repeat the previous example, but now for the latter two timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d8aa7-bd3e-4222-bdd1-ea3d524f78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hmot_partial = HiddenMarkovOT.HM_OT(\n",
    "                            rank_list[1:],\n",
    "                            tau_in = 1e-3,\n",
    "                            tau_out = 1e-3,\n",
    "                            gamma = 80,\n",
    "                            max_iter = 50,\n",
    "                            min_iter = 50,\n",
    "                            device=device,\n",
    "                            alpha = 0.99993,\n",
    "                            dtype = torch.float32,\n",
    "                            printCost = False,\n",
    "                            returnFull = False,\n",
    "                            initialization = 'Full'\n",
    "                           )\n",
    "\n",
    "hmot_partial.gamma_smoothing(C_factors_sequence[1:],\n",
    "                     A_factors_sequence[1:],\n",
    "                     Qs_IC = [None, Qs[2]],\n",
    "                     Qs_freeze = [False, True],\n",
    "                    warmup = False\n",
    "                    )\n",
    "\n",
    "# Plotting results\n",
    "Qs_hmot_partial = [Q.cpu().numpy() for Q in hmot_partial.Q_gammas]\n",
    "Ts_hmot_partial = [T.cpu().numpy() for T in hmot_partial.T_gammas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575531a-29d5-42b6-b56d-080243c6796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_clusters_from_QT(spatial_list[1:], \\\n",
    "                               Qs_hmot_partial, Ts_hmot_partial, \\\n",
    "                               None, clustering_type='reference', \\\n",
    "                               reference_index=1, flip=True, dotsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fc260-54de-4184-8acb-a3ce92f7d4ec",
   "metadata": {},
   "source": [
    "![Alt text](Cluster_Transfer2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64835d04-2507-4089-b863-b5c5b3784855",
   "metadata": {},
   "source": [
    "# Unsupervised Co-cluster Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb390fb-7ba2-433e-97cd-c9e0b4c0fc94",
   "metadata": {},
   "source": [
    "**HM-OT** can also discover co-clusters without any notion of a fixed boundary clustering. Here, we first estimate cluster proportions using K-means, choosing the number of cell-types at each timepoint as a hyperparameter, and use these input estimates of the cluster proportions to infer the unsupervised clusters themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5e13f1-9e9d-4186-896b-0a344f627622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return\n",
    "\n",
    "seed_everything(123)\n",
    "\n",
    "joint = adata_pairs[0]\n",
    "tp1, tp2 = joint.obs['timepoint'].unique()\n",
    "\n",
    "mask1 = joint.obs['timepoint'] == tp1\n",
    "mask2 = joint.obs['timepoint'] == tp2\n",
    "X1 = joint[mask1].obsm['X_pca']\n",
    "X2 = joint[mask2].obsm['X_pca']\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#  choose exact # clusters\n",
    "k1, k2 = 22, 26\n",
    "labels1 = KMeans(n_clusters=k1, random_state=42).fit_predict(X1)\n",
    "labels2 = KMeans(n_clusters=k2, random_state=42).fit_predict(X2)\n",
    "\n",
    "# build prop tensors\n",
    "def get_prop(labels, k):\n",
    "    counts = np.bincount(labels, minlength=k)\n",
    "    return torch.tensor(counts / counts.sum(), dtype=torch.float32)\n",
    "\n",
    "p1 = get_prop(labels1, k1)  \n",
    "p2 = get_prop(labels2, k2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ef3a5-b0c2-40d7-9b85-0fae5ba62348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.clustering as clustering\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "\n",
    "# Taking the best of N Random Initializations (HM-OT problem is non-convex)\n",
    "num_iter = 1\n",
    "\n",
    "gen = torch.Generator(device=device)\n",
    "gen.manual_seed(123)\n",
    "\n",
    "running_min_cost = torch.inf\n",
    "\n",
    "proportions = [p1.to(device), p2.to(device)]\n",
    "\n",
    "for i in range(num_iter):\n",
    "    # Initialize HM-OT\n",
    "    hmot_u = HiddenMarkovOT.HM_OT(\n",
    "                                rank_list = [(p1.shape[0], p2.shape[0])],\n",
    "                                tau_in = 1e-3,\n",
    "                                tau_out = 1e-3,\n",
    "                                gamma = 80,\n",
    "                                max_iter = 200,\n",
    "                                min_iter = 200,\n",
    "                                device=device,\n",
    "                                alpha = 0.9999,\n",
    "                                dtype = torch.float32,\n",
    "                                printCost = False,\n",
    "                                returnFull = False,\n",
    "                                initialization = 'Full',\n",
    "                                proportions=proportions,\n",
    "                                generator=gen\n",
    "                               )\n",
    "    \n",
    "    hmot_u.gamma_smoothing(C_factors_sequence[:-1],\n",
    "                         A_factors_sequence[:-1],\n",
    "                         Qs_IC = [None, None],\n",
    "                         Qs_freeze = [False, False],\n",
    "                        warmup = False\n",
    "                        )\n",
    "    \n",
    "    if hmot_u.compute_total_cost(C_factors_sequence[:-1], A_factors_sequence[:-1]) < running_min_cost:\n",
    "        hmot_unsup = hmot_u\n",
    "\n",
    "\n",
    "# Plotting results\n",
    "Qs_ann = [Q.cpu().numpy() for Q in Qs][:-1]\n",
    "\n",
    "Qs_hmot_unsup = [Q.cpu().numpy() for Q in hmot_unsup.Q_gammas]\n",
    "Ts_hmot_unsup = [T.cpu().numpy() for T in hmot_unsup.T_gammas]\n",
    "\n",
    "plotting.plot_clusters_from_QT(spatial_list[:-1], Qs_hmot_unsup,\n",
    "                               Ts_hmot_unsup, None, clustering_type='reference',\n",
    "                               reference_index=0, flip=True, dotsize=10,\n",
    "                              key_dotsize=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae598e0-874d-4195-91f5-fd6b9d39afda",
   "metadata": {},
   "source": [
    "![Alt text](Unsupervised_Cluster_Demo_E115_125.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (peterenv2)",
   "language": "python",
   "name": "peterenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
