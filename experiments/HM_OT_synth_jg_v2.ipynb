{"cells":[{"cell_type":"markdown","source":["# HM-OT synth example (v3)"],"metadata":{"id":"S5SLeLAsmkLm"},"id":"S5SLeLAsmkLm"},{"cell_type":"markdown","source":["## imports"],"metadata":{"id":"ge1cVNu_mluC"},"id":"ge1cVNu_mluC"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnkGKPDMmlyd","executionInfo":{"status":"ok","timestamp":1749644602845,"user_tz":240,"elapsed":18428,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"0834babd-0e0e-46d9-e921-d291826daa4f"},"id":"AnkGKPDMmlyd","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install scanpy -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Alaq21WIml1U","executionInfo":{"status":"ok","timestamp":1749644606633,"user_tz":240,"elapsed":3783,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"f8355467-8e7f-403e-ada6-88773951897d"},"id":"Alaq21WIml1U","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install moscot -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGupRGOhXVqk","executionInfo":{"status":"ok","timestamp":1749644613842,"user_tz":240,"elapsed":7208,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"395f551e-d321-484a-dd8e-91d597632125"},"id":"EGupRGOhXVqk","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.4/172.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ko12Cd4SXYVG","executionInfo":{"status":"ok","timestamp":1749644620082,"user_tz":240,"elapsed":6239,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"a26dba29-1eb0-4646-99a6-20d2d89b5457"},"id":"ko12Cd4SXYVG","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install diffrax -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdN0cpc5XZIq","executionInfo":{"status":"ok","timestamp":1749644623297,"user_tz":240,"elapsed":3213,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"4a20b50c-bec4-4bde-e325-2297eddf2de8"},"id":"FdN0cpc5XZIq","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from anndata import AnnData\n","import scanpy as sc\n","import numpy as np\n","import torch\n","import sys\n","from scipy.spatial.distance import cdist\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n","from sklearn.cluster import KMeans\n","import sys\n","import importlib\n","import plotly.graph_objects as go\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"DKtPSKjNmwek","executionInfo":{"status":"ok","timestamp":1749647810138,"user_tz":240,"elapsed":40,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"DKtPSKjNmwek","execution_count":17,"outputs":[]},{"cell_type":"code","source":["filehandle_hmot = 'drive/Othercomputers/numac/GitHub/HM-OT/'\n","filehandle_save = 'drive/MyDrive/DX/_data/melanocyte/save/'\n","filehandle_save_factors = 'drive/MyDrive/DX/_data/melanocyte/save_factors/'\n","filehandle_mel = 'drive/MyDrive/DX/_data/melanocyte/cleaned_common_pca_sc/'\n","\n","sys.path.insert(0, filehandle_hmot)\n","sys.path.insert(0, filehandle_save)\n","sys.path.insert(0, filehandle_mel)\n","\n","import src.FRLC as FRLC\n","import src.FRLC.FRLC_multimarginal as FRLC_multimarginal\n","import src.HiddenMarkovOT as HiddenMarkovOT\n","import src.utils.clustering as clustering\n","import src.utils.util_LR as util_LR\n","import src.utils.util_zf as util_zf\n","from src.utils.util_LR import convert_adata\n","import src.plotting as plotting\n","\n","import moscot as mt\n","import moscot.plotting as mpl\n","from moscot.problems.time import TemporalProblem"],"metadata":{"id":"lroSeXNKmwhc","executionInfo":{"status":"ok","timestamp":1749644651964,"user_tz":240,"elapsed":19454,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"lroSeXNKmwhc","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## reload"],"metadata":{"id":"iVv7tgLzm6V0"},"id":"iVv7tgLzm6V0"},{"cell_type":"code","source":["importlib.reload(clustering)\n","importlib.reload(util_LR)\n","importlib.reload(util_zf)\n","importlib.reload(HiddenMarkovOT)\n","importlib.reload(plotting)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTeWavJKmwk0","executionInfo":{"status":"ok","timestamp":1749644651969,"user_tz":240,"elapsed":3,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"af612d6e-ab11-4666-f16f-b9a25bec791e"},"id":"GTeWavJKmwk0","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'src.plotting' from '/content/drive/Othercomputers/numac/GitHub/HM-OT/src/plotting.py'>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'On device: {device}')\n","dtype = torch.float32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7i01w-rmuvY","executionInfo":{"status":"ok","timestamp":1749644651972,"user_tz":240,"elapsed":2,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}},"outputId":"51f74c88-f741-4b58-ff86-134ff1fc9dd2"},"id":"O7i01w-rmuvY","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["On device: cuda\n"]}]},{"cell_type":"markdown","source":["## functions for making synthetic data"],"metadata":{"id":"qWnUkeu2rlkB"},"id":"qWnUkeu2rlkB"},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","device, dtype = \"cpu\", torch.float32\n","\n","n_per_cluster_og=(\n","    [333, 333, 333],                      # 3 clusters\n","    [167, 166, 167, 167, 166, 166],       # 6 clusters\n","    [167, 166, 167, 167, 166, 166],       # 6 clusters\n",")\n","\n","proportions = [\n","    np.array([1000, 1000, 1000]),                                  # t = 0\n","    np.array([500, 500, 500, 500, 500, 500]),                   # t = 1\n","    np.array([500, 500, 500, 500, 500, 500]),                   # t = 2\n","]\n","proportions_tens = [torch.from_numpy(p).type(dtype).to(device) / 3000.0\n","                    for p in proportions]\n","\n","# ────────────────────────────────────────────────────────────────────────────────\n","# ────────────────────────────────────────────────────────────────────────────────\n","##\n","def generate_branching_blobs(\n","    n_per_cluster=(\n","        [1000, 1000, 1000],                      # 3 clusters\n","        [500, 500, 500, 500, 500, 500],       # 6 clusters\n","        [500, 500, 500, 500, 500, 500],       # 6 clusters\n","    ),\n","    std=0.6,\n","    random_seed=0,\n","    CS = 1.0\n","):\n","    rng = np.random.default_rng(random_seed)\n","\n","    # centres[t][cid]  ──>  (x, y)\n","    centres = {\n","        0: {0: np.r_[ -0.11 * CS,  0.11 * CS],\n","            1: np.r_[ -0.11 * CS, -0.22 * CS],\n","            2: np.r_[  0.11 * CS,  0.00 * CS]},\n","\n","        1: {3: np.r_[ -1.0,  1.5],     # children of 0\n","            4: np.r_[ -1.5,  1.0],     # \"\n","            5: np.r_[ -0.5, -2.0],     # children of 1\n","            6: np.r_[ -1.0, -1.5],     # \"\n","            7: np.r_[  1.5,  0.5],     # children of 2\n","            8: np.r_[  1.5, -0.5]},    # \"\n","\n","        2: { 9: np.r_[ -1.5,  2.0],    # child of 3\n","            10: np.r_[ -2.5,  1.0],    # child of 4\n","            11: np.r_[ -0.5, -2.5],    # child of 5\n","            12: np.r_[ -2.0, -1.5],    # child of 6\n","            13: np.r_[  2.0,  1.0],    # child of 7\n","            14: np.r_[  2.0, -1.0]},   # child of 8\n","    }\n","\n","    # which global IDs appear — and in which order — at each time-point\n","    cluster_ids = {\n","        0: [0, 1, 2],                       # founders\n","        1: [3, 4, 5, 6, 7, 8],              # first split\n","        2: [9, 10, 11, 12, 13, 14],         # second split\n","    }\n","\n","    # lineage  (parent → children)   keys are “time-t” *parents*\n","    lineage = {\n","        0: {0: [3, 4],                      # t = 0  →  t = 1\n","            1: [5, 6],\n","            2: [7, 8]},\n","\n","        1: {3:  [9],                        # t = 1  →  t = 2\n","            4: [10],\n","            5: [11],\n","            6: [12],\n","            7: [13],\n","            8: [14]},\n","    }\n","\n","    X_parts, t_parts, c_parts = [], [], []\n","\n","    for t, counts in enumerate(n_per_cluster):\n","        ids_t = cluster_ids[t]\n","        assert len(ids_t) == len(counts), \"counts and ids length mismatch\"\n","\n","        # build each blob using the **true** cluster ID\n","        blobs_t = []\n","        clabels_t = []\n","        for n_pts, cid in zip(counts, ids_t):\n","            blob = rng.normal(loc=centres[t][cid], scale=std, size=(n_pts, 2))\n","            blobs_t.append(blob)\n","            clabels_t.append(np.full(n_pts, cid, dtype=int))\n","\n","        X_parts.append(np.vstack(blobs_t))\n","        t_parts.append(np.full(sum(counts), t, dtype=int))\n","        c_parts.append(np.concatenate(clabels_t))\n","\n","    X              = np.vstack(X_parts)\n","    time_labels    = np.concatenate(t_parts)\n","    cluster_labels = np.concatenate(c_parts)\n","    return X, time_labels, cluster_labels, lineage"],"metadata":{"id":"mL-ACWEKLwAj","executionInfo":{"status":"ok","timestamp":1749645703573,"user_tz":240,"elapsed":97,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"mL-ACWEKLwAj","execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_Q_matrices_from_clusters(X,\n","                                      time_labels,\n","                                      cluster_labels,\n","                                      lineage,\n","                                      device=\"cpu\",\n","                                      dtype=torch.float32):\n","    unique_times = np.unique(time_labels)\n","    n_timepoints = len(unique_times)\n","\n","    cluster_ids_per_time = {}\n","    for t in unique_times:\n","        mask_t = (time_labels == t)\n","        clusters_at_t = np.unique(cluster_labels[mask_t])\n","        cluster_ids_per_time[t] = sorted(clusters_at_t)\n","\n","    Q_matrices = []\n","\n","    for t in unique_times:\n","        mask_t = (time_labels == t)\n","        cells_at_t = np.sum(mask_t)\n","        clusters_at_t = cluster_labels[mask_t]\n","        unique_clusters_t = cluster_ids_per_time[t]\n","        n_clusters_t = len(unique_clusters_t)\n","\n","        cluster_to_col = {cid: i for i, cid in enumerate(unique_clusters_t)}\n","\n","        Q_t = np.zeros((cells_at_t, n_clusters_t))\n","\n","        for i, cluster_id in enumerate(clusters_at_t):\n","            col_idx = cluster_to_col[cluster_id]\n","            Q_t[i, col_idx] = 1.0\n","\n","        # Convert to tensor\n","        # Q_tensor = torch.from_numpy(Q_t).type(dtype).to(device)\n","        Q_matrices.append(Q_t)\n","\n","        # print(f\"Time {t}: {cells_at_t} cells, {n_clusters_t} clusters\")\n","        # print(f\"  Cluster IDs: {unique_clusters_t}\")\n","        # print(f\"  Q matrix shape: {Q_t.shape}\")\n","\n","    return Q_matrices, cluster_ids_per_time"],"metadata":{"id":"-gtoGvDm-IWm","executionInfo":{"status":"ok","timestamp":1749646191043,"user_tz":240,"elapsed":8,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"-gtoGvDm-IWm","execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## other helper functions"],"metadata":{"id":"11yCV4cFFxKG"},"id":"11yCV4cFFxKG"},{"cell_type":"code","source":["def setup_point_clouds_for_waddington_ot(point_cloud_1,\n","                                         point_cloud_2,\n","                                         time_1=0,\n","                                         time_2=1,\n","                                         ct_labels_1=None,\n","                                         ct_labels_2=None):\n","    X_combined = np.vstack([point_cloud_1, point_cloud_2])\n","\n","    time_labels = np.concatenate([\n","        np.full(point_cloud_1.shape[0], time_1),\n","        np.full(point_cloud_2.shape[0], time_2)\n","    ])\n","\n","    cell_ids = np.arange(X_combined.shape[0])\n","\n","    adata = AnnData(X=X_combined)\n","    adata.obs['time_point'] = time_labels\n","    adata.obs['cell_id'] = cell_ids\n","    adata.obs_names = [f\"cell_{i}\" for i in range(X_combined.shape[0])]\n","    adata.var_names = ['dim_1', 'dim_2']\n","\n","    if ct_labels_1 is not None and ct_labels_2 is not None:\n","        combined_ct_labels = np.concatenate([ct_labels_1, ct_labels_2])\n","        adata.obs['celltype'] = combined_ct_labels\n","\n","    return adata"],"metadata":{"id":"8t21aixOFwdS","executionInfo":{"status":"ok","timestamp":1749647061208,"user_tz":240,"elapsed":9,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"8t21aixOFwdS","execution_count":16,"outputs":[]},{"cell_type":"code","source":["def compute_clustering_metrics(true_Q_matrices,\n","                               pred_Q_matrices,\n","                               verbose=True):\n","    assert len(true_Q_matrices) == len(pred_Q_matrices), \\\n","        \"Number of timepoints must match between true and predicted\"\n","\n","    results = {\n","        'timepoint_ami': [],\n","        'timepoint_ari': [],\n","        'overall_ami': None,\n","        'overall_ari': None\n","    }\n","\n","    all_true_labels = []\n","    all_pred_labels = []\n","\n","    for t, (true_Q, pred_Q) in enumerate(zip(true_Q_matrices, pred_Q_matrices)):\n","        if torch.is_tensor(true_Q):\n","            true_Q = true_Q.cpu().detach().numpy()\n","        if torch.is_tensor(pred_Q):\n","            pred_Q = pred_Q.cpu().detach().numpy()\n","\n","        true_labels = np.argmax(true_Q, axis=1)\n","        pred_labels = np.argmax(pred_Q, axis=1)\n","\n","        ami_t = adjusted_mutual_info_score(true_labels, pred_labels)\n","        ari_t = adjusted_rand_score(true_labels, pred_labels)\n","\n","        results['timepoint_ami'].append(ami_t)\n","        results['timepoint_ari'].append(ari_t)\n","\n","        all_true_labels.extend(true_labels)\n","        all_pred_labels.extend(pred_labels)\n","\n","        if verbose:\n","            print(f\"Timepoint {t}:\")\n","            print(f\"  AMI: {ami_t:.4f}\")\n","            print(f\"  ARI: {ari_t:.4f}\")\n","            print(f\"  N cells: {len(true_labels)}\")\n","            print(f\"  True clusters: {len(np.unique(true_labels))}\")\n","            print(f\"  Pred clusters: {len(np.unique(pred_labels))}\")\n","            print()\n","    return results"],"metadata":{"id":"1lPCoS0HIwaj","executionInfo":{"status":"ok","timestamp":1749647836150,"user_tz":240,"elapsed":22,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"1lPCoS0HIwaj","execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## set params"],"metadata":{"id":"MuNrD6Ui_95N"},"id":"MuNrD6Ui_95N"},{"cell_type":"code","source":["### set params\n","\n","FIGSIZE = 16\n","random_state = 42\n","n_timepoints = 3\n","std=0.3\n","\n","CENTER_SCALING_min = 1.0\n","CENTER_SCALING_max = 2.0\n","CS_min = CENTER_SCALING_min\n","CS_max = CENTER_SCALING_max\n","n_CS = 5\n","CS_range = np.linspace(CS_min, CS_max, n_CS)"],"metadata":{"id":"H10X-WgizJEC","executionInfo":{"status":"ok","timestamp":1749646196936,"user_tz":240,"elapsed":4,"user":{"displayName":"Julian Gold","userId":"01597584131251118338"}}},"id":"H10X-WgizJEC","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## experiment loop"],"metadata":{"id":"p6K4K98zARkI"},"id":"p6K4K98zARkI"},{"cell_type":"code","source":["for cs in CS_range:\n","    print(f\"CS = {cs}\")\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # generate data, ground truth objects\n","    X, time_labels, cluster_labels, lineage = generate_branching_blobs(n_per_cluster=n_per_cluster_og,\n","                                                                       std=std,\n","                                                                       random_seed=random_state,\n","                                                                       CS=cs)\n","    Qs_gt, clusters_gt = generate_Q_matrices_from_clusters(X,\n","                                                       time_labels,\n","                                                       cluster_labels,\n","                                                       lineage)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plotting data by timepoint\n","    print(f\"plotting data by timepoint, for CS = {cs}\")\n","    df = pd.DataFrame({\n","    \"x\": X[:, 0],\n","    \"y\": X[:, 1],\n","    \"timepoint\": time_labels\n","    })\n","\n","    palette = sns.color_palette(\"husl\", n_colors=df[\"timepoint\"].nunique())\n","\n","    fig, ax = plt.subplots(figsize=(FIGSIZE, FIGSIZE))\n","    sns.scatterplot(\n","        data=df,\n","        x=\"x\", y=\"y\",\n","        hue=\"timepoint\",\n","        palette=palette,\n","        s=60,\n","        linewidth=0.3, edgecolor=\"k\",\n","        ax=ax\n","    )\n","\n","    ax.set_aspect(\"equal\", adjustable=\"box\")\n","    ax.set_xlabel(r\"$x$\")\n","    ax.set_ylabel(r\"$y$\")\n","    ax.legend(title=\"timepoint\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n","    sns.despine()\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # separate data into timepoints\n","    X1 = X[time_labels == 0]\n","    X2 = X[time_labels == 1]\n","    X3 = X[time_labels == 2]\n","    Ss = [X1, X2, X3]\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plotting data by ground truth cluster\n","    print(f\"plotting data by ground truth cluster, for CS = {cs}\")\n","    labels1_gt_ = np.argmax(Qs_gt[0], axis=1)\n","    labels2_gt_ = np.argmax(Qs_gt[1], axis=1)\n","    labels3_gt_ = np.argmax(Qs_gt[2], axis=1)\n","\n","    labels1_gt = labels1_gt_\n","    labels2_gt = labels2_gt_ + len(set(labels1_gt))\n","    labels3_gt = labels3_gt_ + len(set(labels1_gt)) + len(set(labels2_gt))\n","\n","    gt_clustering_list = [labels1_gt, labels2_gt, labels3_gt]\n","\n","    plotting.plot_all_sc_clusters(spatial_list=Ss,\n","                                clustering_list=gt_clustering_list,\n","                                dotsize=100)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # compute k-means objects\n","    kmeans1 = kmeans = KMeans(n_clusters=3,\n","                          random_state=random_state)\n","    kmeans2 = kmeans = KMeans(n_clusters=6,\n","                            random_state=random_state)\n","    kmeans3 = kmeans = KMeans(n_clusters=6,\n","                            random_state=random_state)\n","\n","    klabels1_ = kmeans1.fit_predict(X1)\n","    klabels2_ = kmeans2.fit_predict(X2)\n","    klabels3_ = kmeans3.fit_predict(X3)\n","\n","    klabels1 = klabels1_\n","    klabels2 = klabels2_ + len(set(klabels1))\n","    klabels3 = klabels3_ + len(set(klabels1)) + len(set(klabels2))\n","\n","    Q1_ann = np.eye(len(set(klabels1_)))[klabels1_]\n","    Q2_ann = np.eye(len(set(klabels2_)))[klabels2_]\n","    Q3_ann = np.eye(len(set(klabels3_)))[klabels3_]\n","    Qs_ann = [Q1_ann, Q2_ann, Q3_ann]\n","\n","    cell_type_labels = np.concatenate([klabels1, klabels2, klabels3])\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # visualize k-means clusters\n","    print(f\"k-means clusters for CS = {cs}\")\n","    plotting.plot_all_sc_clusters(spatial_list=Ss,\n","                              clustering_list=[klabels1, klabels2, klabels3],\n","                              dotsize=100)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # compute HM-OT objects\n","    print(f\"making HM-OT cost matrices for CS = {cs}\")\n","    C_factors_sequence = []\n","\n","    for timepoint in range(2):\n","        tp1 = X[time_labels == timepoint]\n","        tp2 = X[time_labels == timepoint+1]\n","        _X1 = torch.from_numpy(tp1).type(torch.DoubleTensor).to(device)\n","        _X2 = torch.from_numpy(tp2).type(torch.DoubleTensor).to(device)\n","        C12 = torch.cdist(_X1, _X2).to(device)\n","        C12 = C12.to(dtype)\n","        I = torch.eye(C12.shape[1]).to(dtype).to(device)\n","        C_factors_sequence.append(( C12, I ))\n","    '''\n","    A_factors_sequence = []\n","\n","    for timepoint in range(n_timepoints):\n","        tp1 = X[time_labels == timepoint]\n","        _X1 = torch.from_numpy(tp1).type(torch.DoubleTensor).to(device)\n","        A1 = torch.cdist(_X1, _X1).to(device)\n","        A1 = A1.to(dtype)\n","        I = torch.eye(A1.shape[1]).to(dtype).to(device)\n","        A_factors_sequence.append(( A1, I ))\n","    ''';\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # set HM-OT parameters\n","    rank_list = [(3,6), (6,6)]\n","    iter = 100\n","    gamma = 120.0\n","    alpha = 0.0\n","    tau_in = 1e5\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # run HM-OT\n","    print(f\"running HM-OT for CS = {cs}\")\n","    hmot = HiddenMarkovOT.HM_OT(rank_list = rank_list,\n","                                max_iter = iter,\n","                                min_iter = iter,\n","                                device=device,\n","                                alpha = alpha,\n","                                gamma = gamma,\n","                                dtype = dtype,\n","                                printCost = False,\n","                                returnFull = False,\n","                                initialization = 'Full',\n","                                tau_in = tau_in,\n","                                proportions=proportions_tens,\n","                                )\n","\n","    A_factors_sequence = [None] * (n_timepoints)\n","    hmot.gamma_smoothing(C_factors_sequence,\n","                        A_factors_sequence)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # extract HM-OT objects\n","    Qs = hmot.Q_gammas\n","    Ts = hmot.T_gammas\n","\n","    Qs_np = [Q.cpu().detach().numpy() for Q in Qs]\n","    Ts_np = [T.cpu().detach().numpy() for T in Ts]\n","\n","    hmot_labels1_ = np.argmax(Qs_np[0], axis=1)\n","    hmot_labels2_ = np.argmax(Qs_np[1], axis=1)\n","    hmot_labels3_ = np.argmax(Qs_np[2], axis=1)\n","\n","    hmot_labels1 = hmot_labels1_\n","    hmot_labels2 = hmot_labels2_ + len(set(hmot_labels1))\n","    hmot_labels3 = hmot_labels3_ + len(set(hmot_labels1)) + len(set(hmot_labels2))\n","\n","    hmot_clustering_list = [hmot_labels1, hmot_labels2, hmot_labels3]\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plot HM-OT clusters\n","    print(f\"plotting HM-OT clusters for CS = {cs}\")\n","    plotting.plot_all_sc_clusters(spatial_list=Ss,\n","                              clustering_list=hmot_clustering_list,\n","                              dotsize=100)\n","    '''\n","    plotting.plot_clusters_from_QT(Ss,\n","                                Qs_np,\n","                                Ts_np,\n","                                dotsize=500,\n","                                clustering_type='reference',\n","                                reference_index=0)\n","    ''';\n","    '''\n","    plotting.plot_clusters_from_QT(Ss,\n","                                Qs_np,\n","                                Ts_np,\n","                                dotsize=500,\n","                                clustering_type='reference',\n","                                reference_index=1)\n","    ''';\n","\n","    '''\n","    plotting.plot_clusters_from_QT(Ss,\n","                                Qs_np,\n","                                Ts_np,\n","                                dotsize=500,\n","                                clustering_type='reference',\n","                                reference_index=2)\n","    ''';\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plot HM-OT diffmap\n","    print(f\"plotting HM-OT diffmap for CS = {cs}\")\n","    plotting.diffmap_from_QT(Qs_np, Ts_np)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # setup data for W-OT\n","    adata_12 = setup_point_clouds_for_waddington_ot(X1,\n","                                                X2,\n","                                                ct_labels_1=klabels1,\n","                                                ct_labels_2=klabels2)\n","    adata_12.obs[\"celltype\"] = adata_12.obs[\"celltype\"].astype(\"category\")\n","    adata_23 = setup_point_clouds_for_waddington_ot(X2,\n","                                                    X3,\n","                                                    ct_labels_1=klabels2,\n","                                                    ct_labels_2=klabels3)\n","    adata_23.obs[\"celltype\"] = adata_23.obs[\"celltype\"].astype(\"category\")\n","    tp_12 = mt.problems.time.TemporalProblem(adata_12)\n","    tp_23 = mt.problems.time.TemporalProblem(adata_23)\n","\n","    tp_12.prepare(time_key='time_point')\n","    tp_23.prepare(time_key='time_point')\n","\n","    solve_kwargs = {\n","        'epsilon': 0.05,\n","        'tau_a': 1.0,\n","        'tau_b': 1.0,\n","    }\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # running W-OT\n","    print(f\"running W-OT for CS = {cs}\")\n","    tp_12.solve(**solve_kwargs)\n","    pi_12 = tp_12.solutions[(0, 1)].transport_matrix\n","    tp_23.solve(**solve_kwargs)\n","    pi_23 = tp_23.solutions[(0, 1)].transport_matrix\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # make transitions from W-OT\n","    print(f\"making transitions from W-OT for CS = {cs}\")\n","    tp_12.cell_transition(source = 0,\n","                      target = 1,\n","                      source_groups=\"celltype\",\n","                      target_groups=\"celltype\",\n","                      forward=True,\n","                      key_added=\"cell_transition\"\n","                )\n","\n","    tm = adata_12.uns['moscot_results']['cell_transition'][\"cell_transition\"]['transition_matrix']\n","\n","    tm_ordered = tm.loc[np.unique(klabels1), np.unique(klabels2)]\n","    T12_ = tm_ordered.to_numpy()\n","    Q1 = Qs_ann[0] / Qs_ann[0].sum()\n","    T12 = np.diag(np.sum(Q1, axis=0)) @ T12_\n","\n","    tp_23.cell_transition(source = 0,\n","                        target = 1,\n","                        source_groups=\"celltype\",\n","                        target_groups=\"celltype\",\n","                        forward=True,\n","                        key_added=\"cell_transition\"\n","                    )\n","\n","    tm = adata_23.uns['moscot_results']['cell_transition'][\"cell_transition\"]['transition_matrix']\n","\n","    tm_ordered = tm.loc[np.unique(klabels2), np.unique(klabels3)]\n","    T23_ = tm_ordered.to_numpy()\n","    Q2 = Qs_ann[1] / Qs_ann[1].sum()\n","    T23 = np.diag(np.sum(Q2, axis=0)) @ T23_\n","\n","    Ts_wot = [T12, T23]\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plot W-OT diffmap\n","    print(f\"plotting W-OT diffmap for CS = {cs}\")\n","    plotting.diffmap_from_QT(Qs_ann, Ts_wot)\n","\n","    # ────────────────────────────────────────────────────────────────────────────────\n","    # plotting overlayed diffmaps for each method\n","    ## first: HM-OT\n","    print(f\"plotting overlayed diffmap for HM-OT, with CS = {cs}\")\n","    fig, ax = plotting.plot_diffmap_clusters_prime(\n","        X,                   # your (N×2) point‐cloud\n","        time_labels,         # length-N array of 0,1,2…\n","        Qs_np,               # list of factor matrices Qs_np[t]: (n_t × k_t)\n","        Ts_np,               # list of transition matrices Ts_np[t]: (k_t × k_{t+1})\n","        df,                  # your DataFrame with “x”,”y”,”timepoint” columns\n","    )\n","\n","    plt.show()\n","    ## second: W-OT\n","    print(f\"plotting overlayed diffmap for W-OT, with CS = {cs}\")\n","    fig, ax = plotting.plot_diffmap_clusters_prime(\n","        X,                   # your (N×2) point‐cloud\n","        time_labels,         # length-N array of 0,1,2…\n","        Qs_ann,               # list of factor matrices Qs_np[t]: (n_t × k_t)\n","        Ts_wot,               # list of transition matrices Ts_np[t]: (k_t × k_{t+1})\n","        df,                  # your DataFrame with “x”,”y”,”timepoint” columns\n","    )\n","\n","    plt.show()\n","\n","    _ = compute_clustering_metrics(Qs_gt, Qs_ann) # evaluating k-means clusters\n","    _ = compute_clustering_metrics(Qs_gt, Qs_np) # evaluating HM-OT clusters"],"metadata":{"id":"tHCvDSFDA5Tn"},"id":"tHCvDSFDA5Tn","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"peterenv2 [~/.conda/envs/peterenv2/]","language":"python","name":"conda_peterenv2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}