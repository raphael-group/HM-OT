{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f9f074-e952-426b-8aa0-f71a75bbd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import torch\n",
    "import src.FRLC as FRLC\n",
    "import src.FRLC.FRLC_multimarginal as FRLC_multimarginal\n",
    "import src.HiddenMarkovOT\n",
    "\n",
    "import src.utils.util_LR as util_LR\n",
    "from src.utils.util_LR import convert_adata\n",
    "\n",
    "\n",
    "idxs = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ca9c43-7a68-4c04-9806-9d8cdf72a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1733e6c0-b219-4648-b60d-a625cf19f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "\n",
    "import src.utils.clustering\n",
    "import src.HiddenMarkovOT as HiddenMarkovOT\n",
    "import src.plotting as plotting\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import differentiation_map_validation as dmv\n",
    "importlib.reload(dmv)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Filehandle for final differentiation map outputs\n",
    "diffmap_dir = \"/scratch/gpfs/ph3641/hm_ot/ME_unsupervised_diffmap/\"\n",
    "os.makedirs(diffmap_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Cell-type labels for all timepoints + replicates\n",
    "df_cell = pd.read_csv(\"/scratch/gpfs/ph3641/hm_ot/df_cell.csv\")\n",
    "df_cell = df_cell.set_index(\"cell_id\")\n",
    "\n",
    "edge_dir = \"/scratch/gpfs/ph3641/hm_ot/edges.txt\"\n",
    "node_dir = \"/scratch/gpfs/ph3641/hm_ot/nodes.txt\"\n",
    "\n",
    "# Load the data\n",
    "nodes_df = pd.read_csv(node_dir, sep=\"\\t\")\n",
    "edges_df = pd.read_csv(edge_dir, sep=\"\\t\")\n",
    "G, labels_G = dmv.yield_differentiation_graph(nodes_df, edges_df, plotting=False)\n",
    "\n",
    "diffmap_dir = \"/scratch/gpfs/ph3641/hm_ot/ME_supervised_diffmap/\"\n",
    "diffmap_dir_moscot = \"/scratch/gpfs/ph3641/hm_ot/ME_supervised_diffmap_moscot/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60632a6-2aa2-4bef-9b16-ece44f621a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading E8.5 to E8.75\n",
      "loading E8.75 to E9.0\n",
      "loading E9.0 to E9.25\n",
      "loading E9.25 to E9.5\n",
      "loading E9.5 to E9.75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(plotting)\n",
    "\n",
    "timepoints =  ['E8.5', 'E8.75', 'E9.0', 'E9.25', 'E9.5', 'E9.75']\n",
    "replicates = ['embryo_11', 'embryo_14', 'embryo_16', 'embryo_20', 'embryo_24', 'embryo_28']\n",
    "\n",
    "_Ts = []\n",
    "_Ts_m = []\n",
    "\n",
    "_labels = []\n",
    "\n",
    "for i in range(len(timepoints) - 1):\n",
    "    \n",
    "    t1 = timepoints[i]\n",
    "    t2 = timepoints[i + 1]\n",
    "    print(f'loading {t1} to {t2}')\n",
    "    \n",
    "    # Load T matrices (diff map for HM-OT supervised)\n",
    "    T12 = np.load(os.path.join(diffmap_dir, f\"{t1}_{t2}_T.npy\"))\n",
    "    _Ts.append(T12)\n",
    "    \n",
    "    #  Load T matrices (moscot)\n",
    "    T12 = np.load(os.path.join(diffmap_dir_moscot, f\"{t1}_{t2}_T.npy\"))\n",
    "    _Ts_m.append(T12)\n",
    "    \n",
    "    # Load labels\n",
    "    with open(os.path.join(diffmap_dir, f\"{t1}_types.pkl\"), 'rb') as f:\n",
    "        Label_t1 = pickle.load(f)\n",
    "    with open(os.path.join(diffmap_dir, f\"{t2}_types.pkl\"), 'rb') as f:\n",
    "        Label_t2 = pickle.load(f)\n",
    "    \n",
    "    if i == 0:\n",
    "        _labels.append(Label_t1)\n",
    "    _labels.append(Label_t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4198a73e-e624-4370-a9e9-063fc87a15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def score_triples(Qs, Ts, labels, times, G, labels_G, edges_df):\n",
    "    T13 = Ts[0] @ np.diag( 1/ np.sum(Qs[1], axis=0) ) @ Ts[1]\n",
    "    edge_scores, diagonal_edge_scores = dmv.score_from_graph([Qs[0], Qs[2]], [T13], [labels[0], labels[2]],[times[0], times[2]],\n",
    "                                 G, labels_G, edges_df,\n",
    "                                )\n",
    "    npmis = []\n",
    "    diagonal_npmis = []\n",
    "    \n",
    "    for key in edge_scores:\n",
    "        npmis.append(edge_scores[key])\n",
    "    for key in diagonal_edge_scores:\n",
    "        diagonal_npmis.append(diagonal_edge_scores[key])\n",
    "    \n",
    "    print(f'Median NPMI (off-diagonal): {np.median(npmis)}')\n",
    "    print(f'Median NPMI (diagonal): {np.median(diagonal_npmis)}')\n",
    "    print(f'Mean NPMI (off-diagonal): {np.mean(npmis)}')\n",
    "    print(f'Mean NPMI (diagonal): {np.mean(diagonal_npmis)}')\n",
    "    \n",
    "    return edge_scores, diagonal_edge_scores\n",
    "\n",
    "def merge_dicts_of_lists(dict1, dict2):\n",
    "    merged = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged:\n",
    "            merged[key].extend(value)\n",
    "        else:\n",
    "            merged[key] = value.copy()\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f3056f-c0d1-4611-a208-57c9c162c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filehandle_ME = f'/scratch/gpfs/ph3641/hm_ot/adata_JAX_dataset_1.h5ad'\n",
    "sys.path.insert(0, filehandle_ME)\n",
    "adata = sc.read_h5ad(filehandle_ME, backed=\"r\")\n",
    "\n",
    "save_dir = '/scratch/gpfs/ph3641/mouse_embryo/SC_pca_pairs/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for i in range(1, len(timepoints) - 1):\n",
    "    t1, t2, t3 = timepoints[i-1], timepoints[i], timepoints[i+1]\n",
    "    r1, r2, r3 = replicates[i-1], replicates[i], replicates[i+1]\n",
    "    \n",
    "    fname = f\"{save_dir}/subset_{t1}_{t2}_{t3}_r{r1}{r2}{r3}.h5ad\"\n",
    "    if not os.path.exists(fname):\n",
    "        subset_adata = adata[\n",
    "            (adata.obs['day'].isin([t1, t2, t3])) &\n",
    "            (adata.obs['embryo_id'].isin([r1, r2, r3]))\n",
    "        ]\n",
    "        subset_adata = subset_adata.to_memory()\n",
    "        subset_adata.obs = subset_adata.obs.set_index(\"cell_id\")\n",
    "        subset_adata.obs = subset_adata.obs.join(df_cell[['celltype_update']], how=\"left\")\n",
    "        print('-----Starting PCA!-----')\n",
    "        sc.pp.normalize_total(subset_adata, target_sum=1e4)\n",
    "        sc.pp.log1p(subset_adata)\n",
    "        sc.pp.pca(subset_adata, n_comps=30)\n",
    "        print('-----PCA done!-----')\n",
    "        subset_adata.write(fname, compression=\"gzip\")\n",
    "        print(\"Wrote\", fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7dcec-ef1d-4c26-bfd9-259b194e121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing low-rank distance matrix!\n",
      "Computing low-rank distance matrix!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107901/191486830.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  proportions = [torch.sum(torch.tensor(Qs[i]).to(torch.float32), axis=0) for i in range(len(Qs))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 0\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 0\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(util_LR)\n",
    "importlib.reload(HiddenMarkovOT)\n",
    "importlib.reload(FRLC)\n",
    "importlib.reload(FRLC.FRLC_multimarginal)\n",
    "importlib.reload(dmv)\n",
    "\n",
    "import src.utils.clustering as clustering\n",
    "import differentiation_map_validation as dmv\n",
    "from src.FRLC.FRLC_multimarginal import FRLC_LR_opt_multimarginal\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "import copy\n",
    "\n",
    "\"\"\"\n",
    "Loading file / AnnData\n",
    "\"\"\"\n",
    "filehandle_ME = f'/scratch/gpfs/ph3641/hm_ot/adata_JAX_dataset_1.h5ad'\n",
    "sys.path.insert(0, filehandle_ME)\n",
    "adata = sc.read_h5ad(filehandle_ME, backed=\"r\")\n",
    "\n",
    "moscot_diag = {}\n",
    "moscot_offdiag = {}\n",
    "hmot_s_diag = {}\n",
    "hmot_s_offdiag = {}\n",
    "hmot_u_diag = {}\n",
    "hmot_u_offdiag = {}\n",
    "\n",
    "for i in range(1, len(timepoints) - 1):\n",
    "    \n",
    "    t1, t2, t3 = timepoints[i-1], timepoints[i], timepoints[i+1]\n",
    "    r1, r2, r3 = replicates[i-1], replicates[i], replicates[i+1]\n",
    "    \n",
    "    fname = f\"{save_dir}/subset_{t1}_{t2}_{t3}_r{r1}{r2}{r3}.h5ad\"\n",
    "    subset_adata = sc.read_h5ad(fname)\n",
    "    \n",
    "    \"\"\"\n",
    "    rank1 = subset_adata[subset_adata.obs['day'] == t1].obs['celltype_update'].nunique()\n",
    "    rank2 = subset_adata[subset_adata.obs['day'] == t2].obs['celltype_update'].nunique()\n",
    "    rank3 = subset_adata[subset_adata.obs['day'] == t3].obs['celltype_update'].nunique()\n",
    "    \"\"\"\n",
    "    \n",
    "    r_max = 150\n",
    "    C_factors_sequence, A_factors_sequence, Qs, labels, rank_list, _spatial_list = convert_adata(subset_adata,\n",
    "                                                                                                 timepoints=[t1, t2, t3],\n",
    "                                                                                                 replicates=[r1, r2, r3],\n",
    "                                                                                                 timepoint_key = 'day',\n",
    "                                                                                                 replicate_key = 'embryo_id',\n",
    "                                                                                                 feature_key = 'X_pca',\n",
    "                                                                                                cell_type_key = 'celltype_update',\n",
    "                                                                                                spatial = False,\n",
    "                                                                                                dist_eps = 0.02,\n",
    "                                                                                                dist_rank = r_max, \n",
    "                                                                                                device = device)\n",
    "    \n",
    "    proportions = [torch.sum(torch.tensor(Qs[i]).to(torch.float32), axis=0) for i in range(len(Qs))]\n",
    "    \n",
    "    # Annotation types\n",
    "    Qs_ann = [Q.cpu().numpy() for Q in Qs]\n",
    "    \n",
    "    \"\"\"\n",
    "    Supervised HM-OT\n",
    "    \"\"\"\n",
    "    hmot_sup = HiddenMarkovOT.HM_OT(rank_list, \n",
    "                                tau_in = 1e-3,\n",
    "                                tau_out = 1e-3,\n",
    "                                gamma= 7,\n",
    "                                max_iter= 20,\n",
    "                                min_iter= 20,\n",
    "                                device=device,\n",
    "                                dtype=torch.float32,\n",
    "                                printCost=False,\n",
    "                                returnFull=False,\n",
    "                                alpha=0.0,\n",
    "                                initialization='Full'\n",
    "                               )\n",
    "    \n",
    "    hmot_sup.impute_annotated_transitions(C_factors_sequence, \n",
    "                                     A_factors_sequence, \n",
    "                                     copy.deepcopy(Qs))\n",
    "    \"\"\"\n",
    "    Unsupervised HM-OT\n",
    "    \"\"\"\n",
    "    hmot = HiddenMarkovOT.HM_OT(\n",
    "                                rank_list, \n",
    "                                tau_in = 1e-3,\n",
    "                                tau_out = 1e-3,\n",
    "                                gamma= 80,\n",
    "                                max_iter= 50,\n",
    "                                min_iter= 50,\n",
    "                                device=device,\n",
    "                                dtype=torch.float32,\n",
    "                                printCost=False,\n",
    "                                returnFull=False,\n",
    "                                alpha=0.0,\n",
    "                                initialization='Full',\n",
    "                                proportions = proportions,\n",
    "                                max_inner_iters_B = 200,\n",
    "                                max_inner_iters_R = 200,\n",
    "                               )\n",
    "\n",
    "    '''\n",
    "    hmot.gamma_smoothing(C_factors_sequence, A_factors_sequence, \n",
    "                         Qs_freeze = [False, False, False],\n",
    "                         Qs_IC = [Qs[0], Qs[1], Qs[2]], \n",
    "                         warmup = True)'''\n",
    "\n",
    "    # Evaluate middle to interpret\n",
    "    hmot.gamma_smoothing(C_factors_sequence, A_factors_sequence, \n",
    "                         Qs_IC = [Qs[0], Qs[1], Qs[2]],\n",
    "                         Qs_freeze = [True, False, True],\n",
    "                        warmup = False)\n",
    "    \n",
    "    # Unsupervised types and transitions\n",
    "    Qs_u = [Q_.cpu().numpy() for Q_ in hmot.Q_gammas]\n",
    "    Ts = [T.cpu().numpy() for T in hmot.T_gammas]\n",
    "    \n",
    "    # Moscot and hmot supervised transitions\n",
    "    Ts_m = [T for T in _Ts_m[i-1:i+1]]\n",
    "    Ts_s = [T.cpu().numpy() for T in hmot_sup.T_gammas]\n",
    "    \n",
    "    # Plot diffmap\n",
    "    plotting.diffmap_from_QT([ Qs_ann[0], Qs_ann[1], Qs_ann[2] ],\n",
    "                         Ts_s,\n",
    "                         [labels[0], labels[1], labels[2]],\n",
    "                         dsf=0.01,\n",
    "                        fontsize=5,\n",
    "                        linethick_factor=55,\n",
    "                        title=f\"Alignment from {timepoints[0]} to {timepoints[-1]}\",\n",
    "                        save_name=os.path.join(f'/scratch/gpfs/ph3641/hm_ot/ME_supervised_figs/supervised_{timepoints[0]}_{timepoints[-1]}.svg') )\n",
    "    \n",
    "    plotting.diffmap_from_QT([ Qs_ann[0], Qs_u[1], Qs_ann[2] ],\n",
    "                         Ts,\n",
    "                         [None, None, None],\n",
    "                         dsf=0.01,\n",
    "                        fontsize=5,\n",
    "                        linethick_factor=55,\n",
    "                        title=f\"Alignment from {timepoints[0]} to {timepoints[-1]}\",\n",
    "                        save_name=os.path.join(f'/scratch/gpfs/ph3641/hm_ot/ME_supervised_figs/unsupervised_{timepoints[0]}_{timepoints[-1]}.svg') )\n",
    "    \n",
    "    plotting.diffmap_from_QT([ Qs_ann[0], Qs_ann[1], Qs_ann[2] ],\n",
    "                         Ts_m,\n",
    "                         [labels[0], labels[1], labels[2]],\n",
    "                         dsf=0.01,\n",
    "                        fontsize=5,\n",
    "                        linethick_factor=55,\n",
    "                        title=f\"Alignment from {timepoints[0]} to {timepoints[-1]}\",\n",
    "                        save_name=os.path.join(f'/scratch/gpfs/ph3641/hm_ot/ME_supervised_figs/moscot_{timepoints[0]}_{timepoints[-1]}.svg') )\n",
    "    \n",
    "    clus_u = clustering.max_likelihood_clustering([Qs_u[1]], mode='standard')[0]\n",
    "    clus_ann = clustering.max_likelihood_clustering([Qs_ann[1]], mode='standard')[0]\n",
    "    \n",
    "    print(f\"ami of predictions: {ami(clus_u, clus_ann):.3f} for slice {i} (gamma)\")\n",
    "    print(f\"ari of predictions: {ari(clus_u, clus_ann):.3f} for slice {i} (gamma)\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1700c8-c4ff-47ea-a3d5-625dc3896c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (peterenv2)",
   "language": "python",
   "name": "peterenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
